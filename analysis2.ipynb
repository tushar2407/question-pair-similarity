{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import itertools\n",
    "import re\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "\n",
    "import keras.layers as lyr\n",
    "from keras.models import Model, load_model\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = './dataset/'\n",
    "# train = pd.read_csv(f'{BASE_DIR}train.csv')\n",
    "# test = pd.read_csv(f'{BASE_DIR}test.csv')\n",
    "train = pd.read_csv(f'{BASE_DIR}train_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['id'] = train['id'].apply(str)\n",
    "# test['test_id'] = test['test_id'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.concat((train, test))\n",
    "df = train\n",
    "df['question1'].fillna('', inplace=True)\n",
    "df['question2'].fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_vectorizer = CountVectorizer(max_features=10000-1).fit(\n",
    "    itertools.chain(\n",
    "        df['question1'], \n",
    "        df['question2']\n",
    "        )\n",
    "    )\n",
    "other_index = len(counts_vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_tokenizer = re.compile(counts_vectorizer.token_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padded_seqs(texts, max_len=10):\n",
    "    seqs = texts.apply(\n",
    "        lambda s: \n",
    "            [\n",
    "                counts_vectorizer.vocabulary_[w] if w in counts_vectorizer.vocabulary_ else other_index\n",
    "                for w in words_tokenizer.findall(s.lower())\n",
    "            ]\n",
    "        )\n",
    "    return pad_sequences(seqs, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train, X1_val, X2_train, X2_val, y_train, y_val = \\\n",
    "    train_test_split(\n",
    "        create_padded_seqs(df[df['id'].notnull()]['question1']), \n",
    "        create_padded_seqs(df[df['id'].notnull()]['question2']),\n",
    "        df[df['id'].notnull()]['is_duplicate'].values,\n",
    "        stratify=df[df['id'].notnull()]['is_duplicate'].values,\n",
    "        test_size=0.3, random_state=1989\n",
    "    )\n",
    "X1_val, X1_test, X2_val, X2_test, y_val, y_test = \\\n",
    "    train_test_split(\n",
    "        X1_val, \n",
    "        X2_val,\n",
    "        y_val,\n",
    "        stratify=y_val,\n",
    "        test_size=0.5, random_state=1989\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 10)]         0           []                               \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, 10)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)        (None, 10, 100)      1000000     ['input_5[0][0]',                \n",
      "                                                                  'input_6[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  (None, 256)          365568      ['embedding_2[0][0]',            \n",
      "                                                                  'embedding_2[1][0]']            \n",
      "                                                                                                  \n",
      " multiply_2 (Multiply)          (None, 256)          0           ['lstm_2[0][0]',                 \n",
      "                                                                  'lstm_2[1][0]']                 \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 16)           4112        ['multiply_2[0][0]']             \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 1)            17          ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,369,697\n",
      "Trainable params: 1,369,697\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input1_tensor = lyr.Input(X1_train.shape[1:])\n",
    "input2_tensor = lyr.Input(X2_train.shape[1:])\n",
    "\n",
    "words_embedding_layer = lyr.Embedding(X1_train.max() + 1, 100)\n",
    "seq_embedding_layer = lyr.LSTM(256, activation='tanh')\n",
    "\n",
    "seq_embedding = lambda tensor: seq_embedding_layer(words_embedding_layer(tensor))\n",
    "\n",
    "merge_layer = lyr.multiply([seq_embedding(input1_tensor), seq_embedding(input2_tensor)])\n",
    "\n",
    "dense1_layer = lyr.Dense(16, activation='sigmoid')(merge_layer)\n",
    "ouput_layer = lyr.Dense(1, activation='sigmoid')(dense1_layer)\n",
    "\n",
    "model = Model([input1_tensor, input2_tensor], ouput_layer)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "2212/2212 - 303s - loss: 0.5019 - val_loss: 0.4658 - 303s/epoch - 137ms/step\n",
      "Epoch 2/6\n",
      "2212/2212 - 293s - loss: 0.4267 - val_loss: 0.4373 - 293s/epoch - 132ms/step\n",
      "Epoch 3/6\n",
      "2212/2212 - 301s - loss: 0.3797 - val_loss: 0.4239 - 301s/epoch - 136ms/step\n",
      "Epoch 4/6\n",
      "2212/2212 - 271s - loss: 0.3418 - val_loss: 0.4252 - 271s/epoch - 122ms/step\n",
      "Epoch 5/6\n",
      "2212/2212 - 303s - loss: 0.3048 - val_loss: 0.4317 - 303s/epoch - 137ms/step\n",
      "Epoch 6/6\n",
      "2212/2212 - 274s - loss: 0.2694 - val_loss: 0.4517 - 274s/epoch - 124ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28cd657daf0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.fit([X1_train, X2_train], y_train, \n",
    "#           validation_data=([X1_val, X2_val], y_val), \n",
    "#           batch_size=128, epochs=6, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x28c862fdfd0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(\"./models/analysis2/model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict([X1_test, X2_test],128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.where(y_pred>0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/analysis2/model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/analysis2/model\\assets\n",
      "d:\\college\\Sem_5\\NLP\\Project\\venv\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "d:\\college\\Sem_5\\NLP\\Project\\venv\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000028C8282F550> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "# model.save_weights('./models/analysis2/model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score :  0.8078907885842415\n",
      "F1 Score :  0.7531565121599864\n",
      "Precision :  0.7165430506288294\n",
      "Recall :  0.793713163064833\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "print(\"Accuracy Score : \", accuracy_score(y_test, y_pred))\n",
    "print(\"F1 Score : \", f1_score(y_test, y_pred))\n",
    "print(\"Precision : \", precision_score(y_test, y_pred))\n",
    "print(\"Recall : \", recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_model = Model([input1_tensor, input2_tensor], merge_layer)\n",
    "# features_model.compile(loss='mse', optimizer='adam')\n",
    "# F_train = features_model.predict([X1_train, X2_train], batch_size=128)\n",
    "# F_val = features_model.predict([X1_val, X2_val], batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# pickle.dump(merge_layer, open(\"./models/analysis2/merge_layer_unprocessed.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XgBoost on top (NA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dTrain = xgb.DMatrix(F_train, label=y_train)\n",
    "dVal = xgb.DMatrix(F_val, label=y_val)\n",
    "xgb_params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'booster': 'gbtree',\n",
    "    'eval_metric': 'logloss',\n",
    "    'eta': 0.1, \n",
    "    'max_depth': 9,\n",
    "    'subsample': 0.9,\n",
    "    'colsample_bytree': 1 / F_train.shape[1]**0.5,\n",
    "    'min_child_weight': 5,\n",
    "    'silent': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:55:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-logloss:0.67954\tval-logloss:0.68054\n",
      "[10]\ttrain-logloss:0.60924\tval-logloss:0.61783\n",
      "[20]\ttrain-logloss:0.57928\tval-logloss:0.59478\n",
      "[30]\ttrain-logloss:0.56041\tval-logloss:0.58232\n",
      "[40]\ttrain-logloss:0.54551\tval-logloss:0.57386\n",
      "[50]\ttrain-logloss:0.53390\tval-logloss:0.56806\n",
      "[60]\ttrain-logloss:0.52326\tval-logloss:0.56331\n",
      "[70]\ttrain-logloss:0.51404\tval-logloss:0.55969\n",
      "[80]\ttrain-logloss:0.50502\tval-logloss:0.55628\n",
      "[90]\ttrain-logloss:0.49600\tval-logloss:0.55318\n",
      "[100]\ttrain-logloss:0.48787\tval-logloss:0.55078\n",
      "[110]\ttrain-logloss:0.48027\tval-logloss:0.54855\n",
      "[120]\ttrain-logloss:0.47239\tval-logloss:0.54634\n",
      "[130]\ttrain-logloss:0.46542\tval-logloss:0.54458\n",
      "[140]\ttrain-logloss:0.45913\tval-logloss:0.54299\n",
      "[150]\ttrain-logloss:0.45284\tval-logloss:0.54142\n",
      "[160]\ttrain-logloss:0.44732\tval-logloss:0.54015\n",
      "[170]\ttrain-logloss:0.44239\tval-logloss:0.53909\n",
      "[180]\ttrain-logloss:0.43682\tval-logloss:0.53787\n",
      "[190]\ttrain-logloss:0.43191\tval-logloss:0.53681\n",
      "[200]\ttrain-logloss:0.42669\tval-logloss:0.53568\n",
      "[210]\ttrain-logloss:0.42174\tval-logloss:0.53462\n",
      "[220]\ttrain-logloss:0.41804\tval-logloss:0.53383\n",
      "[230]\ttrain-logloss:0.41472\tval-logloss:0.53312\n",
      "[240]\ttrain-logloss:0.41100\tval-logloss:0.53240\n",
      "[250]\ttrain-logloss:0.40727\tval-logloss:0.53169\n",
      "[260]\ttrain-logloss:0.40422\tval-logloss:0.53118\n",
      "[270]\ttrain-logloss:0.40057\tval-logloss:0.53067\n",
      "[280]\ttrain-logloss:0.39738\tval-logloss:0.53011\n",
      "[290]\ttrain-logloss:0.39403\tval-logloss:0.52973\n",
      "[300]\ttrain-logloss:0.39101\tval-logloss:0.52926\n",
      "[310]\ttrain-logloss:0.38841\tval-logloss:0.52886\n",
      "[320]\ttrain-logloss:0.38653\tval-logloss:0.52845\n",
      "[330]\ttrain-logloss:0.38391\tval-logloss:0.52795\n",
      "[340]\ttrain-logloss:0.38103\tval-logloss:0.52745\n",
      "[350]\ttrain-logloss:0.37840\tval-logloss:0.52698\n",
      "[360]\ttrain-logloss:0.37602\tval-logloss:0.52662\n",
      "[370]\ttrain-logloss:0.37349\tval-logloss:0.52628\n",
      "[380]\ttrain-logloss:0.37068\tval-logloss:0.52587\n",
      "[390]\ttrain-logloss:0.36777\tval-logloss:0.52550\n",
      "[400]\ttrain-logloss:0.36590\tval-logloss:0.52520\n",
      "[410]\ttrain-logloss:0.36388\tval-logloss:0.52476\n",
      "[420]\ttrain-logloss:0.36118\tval-logloss:0.52449\n",
      "[430]\ttrain-logloss:0.35891\tval-logloss:0.52403\n",
      "[440]\ttrain-logloss:0.35664\tval-logloss:0.52374\n",
      "[450]\ttrain-logloss:0.35425\tval-logloss:0.52339\n",
      "[460]\ttrain-logloss:0.35248\tval-logloss:0.52311\n",
      "[470]\ttrain-logloss:0.35051\tval-logloss:0.52290\n",
      "[480]\ttrain-logloss:0.34882\tval-logloss:0.52265\n",
      "[490]\ttrain-logloss:0.34708\tval-logloss:0.52246\n",
      "[500]\ttrain-logloss:0.34517\tval-logloss:0.52216\n",
      "[510]\ttrain-logloss:0.34357\tval-logloss:0.52193\n",
      "[520]\ttrain-logloss:0.34138\tval-logloss:0.52163\n",
      "[530]\ttrain-logloss:0.33857\tval-logloss:0.52141\n",
      "[540]\ttrain-logloss:0.33619\tval-logloss:0.52116\n",
      "[550]\ttrain-logloss:0.33414\tval-logloss:0.52078\n",
      "[560]\ttrain-logloss:0.33247\tval-logloss:0.52051\n",
      "[570]\ttrain-logloss:0.33061\tval-logloss:0.52035\n",
      "[580]\ttrain-logloss:0.32884\tval-logloss:0.52009\n",
      "[590]\ttrain-logloss:0.32675\tval-logloss:0.51988\n",
      "[600]\ttrain-logloss:0.32463\tval-logloss:0.51970\n",
      "[610]\ttrain-logloss:0.32286\tval-logloss:0.51964\n",
      "[620]\ttrain-logloss:0.32084\tval-logloss:0.51943\n",
      "[630]\ttrain-logloss:0.31888\tval-logloss:0.51924\n",
      "[640]\ttrain-logloss:0.31766\tval-logloss:0.51909\n",
      "[650]\ttrain-logloss:0.31644\tval-logloss:0.51894\n",
      "[660]\ttrain-logloss:0.31480\tval-logloss:0.51868\n",
      "[670]\ttrain-logloss:0.31359\tval-logloss:0.51849\n",
      "[680]\ttrain-logloss:0.31135\tval-logloss:0.51823\n",
      "[690]\ttrain-logloss:0.30989\tval-logloss:0.51800\n",
      "[700]\ttrain-logloss:0.30797\tval-logloss:0.51767\n",
      "[710]\ttrain-logloss:0.30668\tval-logloss:0.51753\n",
      "[720]\ttrain-logloss:0.30549\tval-logloss:0.51736\n",
      "[730]\ttrain-logloss:0.30434\tval-logloss:0.51718\n",
      "[740]\ttrain-logloss:0.30273\tval-logloss:0.51697\n",
      "[750]\ttrain-logloss:0.30114\tval-logloss:0.51679\n",
      "[760]\ttrain-logloss:0.29995\tval-logloss:0.51665\n",
      "[770]\ttrain-logloss:0.29857\tval-logloss:0.51653\n",
      "[780]\ttrain-logloss:0.29687\tval-logloss:0.51642\n",
      "[790]\ttrain-logloss:0.29531\tval-logloss:0.51618\n",
      "[800]\ttrain-logloss:0.29371\tval-logloss:0.51597\n",
      "[810]\ttrain-logloss:0.29181\tval-logloss:0.51579\n",
      "[820]\ttrain-logloss:0.29006\tval-logloss:0.51552\n",
      "[830]\ttrain-logloss:0.28923\tval-logloss:0.51541\n",
      "[840]\ttrain-logloss:0.28751\tval-logloss:0.51533\n",
      "[847]\ttrain-logloss:0.28633\tval-logloss:0.51530\n"
     ]
    }
   ],
   "source": [
    "bst = xgb.train(xgb_params, dTrain, 1000,  [(dTrain,'train'), (dVal,'val')],\n",
    "                verbose_eval=10, early_stopping_rounds=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(bst, open(\"./models/analysis2/xgb_unprocessed.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>test_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id  qid1  qid2                                          question1  \\\n",
       "0  0   1.0   2.0  What is the step by step guide to invest in sh...   \n",
       "1  1   3.0   4.0  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2  2   5.0   6.0  How can I increase the speed of my internet co...   \n",
       "3  3   7.0   8.0  Why am I mentally very lonely? How can I solve...   \n",
       "4  4   9.0  10.0  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate test_id  \n",
       "0  What is the step by step guide to invest in sh...           0.0     NaN  \n",
       "1  What would happen if the Indian government sto...           0.0     NaN  \n",
       "2  How can Internet speed be increased by hacking...           0.0     NaN  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...           0.0     NaN  \n",
       "4            Which fish would survive in salt water?           0.0     NaN  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_test = features_model.predict([X1_test, X2_test], batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dTest = xgb.DMatrix(F_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\college\\Sem_5\\NLP\\Project\\venv\\lib\\site-packages\\xgboost\\core.py:105: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_duplicate_true</th>\n",
       "      <th>is_duplicate_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.504413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.082391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.154923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.237311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.297524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_duplicate_true  is_duplicate_pred\n",
       "0                0.0           0.504413\n",
       "1                0.0           0.082391\n",
       "2                0.0           0.154923\n",
       "3                1.0           0.237311\n",
       "4                0.0           0.297524"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub = pd.DataFrame({\n",
    "        'is_duplicate_true': y_test,\n",
    "        'is_duplicate_pred': bst.predict(dTest, ntree_limit=bst.best_ntree_limit)\n",
    "    })\n",
    "\n",
    "df_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAUHklEQVR4nO3dfZBdZX3A8e9PIojEJmjsDpOkho7RlpK+wA7gOGM3xtGADnGmSGFQExqbqUVLNW2N9Q86Wqc4DjLqWG1aGMChrkhtyQhWmcgOY6ehErWEF19WjJIUiQqmXUBp7K9/3Ae8LLvZu/dt793n+5nZ2XOe85xznt++/M5zn/PccyMzkSTV4VkL3QBJUv+Y9CWpIiZ9SaqISV+SKmLSl6SKLFnoBhzNihUrcs2aNW3v/+ijj3LCCSd0r0FDwJjrYMx1aDfmvXv3/igzXzjTtoFO+mvWrOHOO+9se/+JiQnGxsa616AhYMx1MOY6tBtzRHxvtm0O70hSRUz6klQRk74kVcSkL0kVMelLUkVM+pJUkTmTfkRcHRGHIuLuprIPRsQ3IuKuiPjniFjetO3dETEZEd+MiNc0lW8sZZMRsaPrkUiS5tRKT/8aYOO0sluBUzPzN4FvAe8GiIhTgAuA3yj7/G1EHBMRxwAfA84GTgEuLHUlSX00Z9LPzNuBh6eVfTEzj5TVPcCqsrwJGM/Mn2Xmd4FJ4IzyNZmZ92fmE8B4qStJ6qNuvCP3D4BPl+WVNC4CTzpQygAemFZ+ZhfOPTDW7Lj5qeX9l792AVsiSbPrKOlHxHuAI8D13WkORMQ2YBvAyMgIExMTbR9ramqqo/3nY/u6I08t9+ucM+lnzIPCmOtgzN3RdtKPiC3A64AN+YvPXDwIrG6qtqqUcZTyp8nMncBOgNHR0ezkWRv9fFbHluae/kX9OedMfD5JHYy5Dr2Iua0pmxGxEfgL4NzMfKxp0y7ggog4LiJOBtYC/wF8BVgbESdHxLE0bvbu6qzpkqT5mrOnHxGfAsaAFRFxALiMxmyd44BbIwJgT2b+UWbeExE3APfSGPa5JDN/Xo7zNuALwDHA1Zl5Tw/ikSQdxZxJPzMvnKH4qqPUfz/w/hnKbwFumVfrJEldNdDP018MnNUjaZD4GAZJqog9/Xmy5y5pmNnTl6SKmPQlqSImfUmqiGP6feT9AEkLzaS/QLwASFoIJv0eaE7okjRIHNOXpIrY0x8ADvVI6hd7+pJUEXv6HXDsXtKwsacvSRUx6UtSRUz6klQRk74kVcSkL0kVcfZOC5ylI2mxMOkPGN+oJamXHN6RpIqY9CWpIiZ9SaqIY/qzGISbt47vS+o2e/qSVBGTviRVZM6kHxFXR8ShiLi7qez5EXFrRHy7fD+xlEdEfCQiJiPirog4rWmfzaX+tyNic2/CkSQdTSs9/WuAjdPKdgC7M3MtsLusA5wNrC1f24CPQ+MiAVwGnAmcAVz25IVCktQ/cyb9zLwdeHha8Sbg2rJ8LfD6pvLrsmEPsDwiTgJeA9yamQ9n5iPArTzzQiJJ6rF2Z++MZOaDZfkHwEhZXgk80FTvQCmbrfwZImIbjVcJjIyMMDEx0WYTYWpqqu39t6870vZ5e6HVODqJeVgZcx2MuTs6nrKZmRkR2Y3GlOPtBHYCjI6O5tjYWNvHmpiYoN39twzAlM1m+y8aa6leJzEPK2OugzF3R7tJ/6GIOCkzHyzDN4dK+UFgdVO9VaXsIDA2rXyizXNXyTn7krqh3Smbu4AnZ+BsBm5qKn9zmcVzFnC4DAN9AXh1RJxYbuC+upRJkvpozp5+RHyKRi99RUQcoDEL53LghojYCnwPOL9UvwU4B5gEHgMuBsjMhyPifcBXSr33Zub0m8Nqw/R3Dl+z8YQFaomkYTBn0s/MC2fZtGGGuglcMstxrgaunlfrJEld5bN3htDRngu07+Dhp25CO/YvaTofwyBJFam+pz8IT9OUpH6xpy9JFTHpS1JFTPqSVBGTviRVxKQvSRUx6UtSRaqfsrmY+ZA2SdPZ05ekipj0JakiJn1JqohJX5IqYtKXpIqY9CWpIk7ZrMRs0zed1inVxZ6+JFXEpC9JFXF4p0K9+OAYh4mk4WBPX5IqYtKXpIqY9CWpIiZ9SaqISV+SKtLR7J2IeAfwFiCBfcDFwEnAOPACYC/wpsx8IiKOA64DTgd+DPx+Zu7v5PzqLmfgSItf2z39iFgJ/AkwmpmnAscAFwAfAK7MzBcDjwBbyy5bgUdK+ZWlniSpjzod3lkCHB8RS4DnAg8CrwRuLNuvBV5fljeVdcr2DRERHZ5fkjQPkZnt7xxxKfB+4HHgi8ClwJ7SmyciVgOfz8xTI+JuYGNmHijbvgOcmZk/mnbMbcA2gJGRkdPHx8fbbt/U1BRLly49ap19Bw+3ffxBNHI8PPR458dZt3LZjOXNP6/mOrOV90Mrv+fFxpjr0G7M69ev35uZozNta3tMPyJOpNF7Pxn4CfAZYGO7x3tSZu4EdgKMjo7m2NhY28eamJhgpv2f/o7UxfWm5O3rjnDFvs5j2n/R2IzlW5rH/ZvqzFbeD7P9nhczY65DL2LuJDu8CvhuZv4QICI+C7wcWB4RSzLzCLAKOFjqHwRWAwfKcNAyGjd0NYB68agGSQuvkzH97wNnRcRzy9j8BuBe4DbgvFJnM3BTWd5V1inbv5SdjC1Jkuat7Z5+Zt4RETcCXwWOAF+jMSxzMzAeEX9dyq4qu1wFfDIiJoGHacz00SLnNFBpsHQ0+JuZlwGXTSu+Hzhjhro/Bd7QyfkkSZ3xHbmSVJHFNXVFfeXNXmn4mPS1IFoZ6/d+gNR9Du9IUkVM+pJUEZO+JFXEMX0tOMfupf4x6avrBmVWjxcT6ZlM+uqbQbkYSDUz6Wso2GuXusMbuZJUEZO+JFXEpC9JFXFMXwNlvjd71+y4me3rjrBlx82O9UstsKcvSRWxp6+h49RPqX329CWpIvb0pS7zPQUaZCZ9VW22BO3z/rVYmfRVhfkm8VaO0wteSNRrJn1VxxvBqplJX1oA9ui1UEz6WjR61YP3lYEWE5O+NKB8NaBeMOlLXdDJTWBfSaifTPpSD5nQNWg6ekduRCyPiBsj4hsRcV9EvCwinh8Rt0bEt8v3E0vdiIiPRMRkRNwVEad1JwRJUqs6fQzDh4F/zcxfA34LuA/YAezOzLXA7rIOcDawtnxtAz7e4bklSfPU9vBORCwDXgFsAcjMJ4AnImITMFaqXQtMAO8CNgHXZWYCe8qrhJMy88G2Wy9VYvow0VyPk/YmsGYTjRzcxo4Rvw3sBO6l0cvfC1wKHMzM5aVOAI9k5vKI+BxweWZ+uWzbDbwrM++cdtxtNF4JMDIycvr4+Hhb7QOYmppi6dKlzyjfd/Bw28ccdCPHw0OPL3Qr+qvmmNetXDbj9ua/8dnqDJvZ/p8Xs3ZjXr9+/d7MHJ1pWyc3cpcApwFvz8w7IuLD/GIoB4DMzIiY11UlM3fSuJgwOjqaY2NjbTdwYmKCJ/d/ek9p8d6/3r7uCFfsW7zxzaTmmPdfNDbj9i3NPf1Z6gyb5v/nWvQi5k7+Uw4ABzLzjrJ+I42k/9CTwzYRcRJwqGw/CKxu2n9VKZPUBa3OFHLop25t38jNzB8AD0TES0vRBhpDPbuAzaVsM3BTWd4FvLnM4jkLOOx4viT1V6evid8OXB8RxwL3AxfTuJDcEBFbge8B55e6twDnAJPAY6WuJKmPOkr6mfl1YKabBRtmqJvAJZ2cT5LUGT8uUZIqYtKXpIrUNc9N0tM4k6c+9vQlqSImfUmqiMM70hAbhA9z13Cxpy9JFTHpS1JFTPqSVBGTviRVZFHfyN138PDTHjErSbWzpy9JFTHpS1JFFvXwjqTW+UiGOtjTl6SKmPQlqSImfUmqiElfkipi0pekipj0JakiJn1Jqojz9CUdlfP3FxeTvqRnmO+Hs3gxGB4mfUkt81O4hp9j+pJUkY6TfkQcExFfi4jPlfWTI+KOiJiMiE9HxLGl/LiyPlm2r+n03JKk+elGT/9S4L6m9Q8AV2bmi4FHgK2lfCvwSCm/stSTJPVRR0k/IlYBrwX+oawH8ErgxlLlWuD1ZXlTWads31DqS5L6JDKz/Z0jbgT+Bnge8GfAFmBP6c0TEauBz2fmqRFxN7AxMw+Ubd8BzszMH0075jZgG8DIyMjp4+Pjbbfv0MOHeejxtncfSiPHY8wVGLSY161c9tTyvoOH56zTjqmpKZYuXdrRMYZNuzGvX79+b2aOzrSt7dk7EfE64FBm7o2IsXaPM11m7gR2AoyOjubYWPuH/uj1N3HFvromKG1fd8SYKzBwMe97tGll5nbtv2iso1NMTEzQST4YRr2IuZO/mpcD50bEOcBzgF8CPgwsj4glmXkEWAUcLPUPAquBAxGxBFgG/LiD80uS5qntMf3MfHdmrsrMNcAFwJcy8yLgNuC8Um0zcFNZ3lXWKdu/lJ2MLUmS5q0X8/TfBbwzIiaBFwBXlfKrgBeU8ncCO3pwbknSUXRlUDAzJ4CJsnw/cMYMdX4KvKEb55Mktcd35EpSRUz6klQRk74kVcSkL0kVMelLUkUG6C19kmrkh7H0lz19SaqIPX1JfWGPfjDY05ekipj0JakiDu9I6js/YH3h2NOXpIqY9CWpIg7vSBoYzvDpPXv6klQRk74kVcThHUkDyaGe3rCnL0kVMelLUkVM+pJUEZO+JFXEpC9JFXH2jqSBt2bHzWxfd4Qt057Z0zyrx9k+rTHpSxpaPrht/hzekaSKtJ30I2J1RNwWEfdGxD0RcWkpf35E3BoR3y7fTyzlEREfiYjJiLgrIk7rVhCSpNZ00tM/AmzPzFOAs4BLIuIUYAewOzPXArvLOsDZwNrytQ34eAfnliS1oe2kn5kPZuZXy/L/APcBK4FNwLWl2rXA68vyJuC6bNgDLI+Ik9o9vyRp/iIzOz9IxBrgduBU4PuZubyUB/BIZi6PiM8Bl2fml8u23cC7MvPOacfaRuOVACMjI6ePj4+33a5DDx/mocfb3n0ojRyPMVfAmI9u3cplvW1Mn0xNTbF06dJ577d+/fq9mTk607aOZ+9ExFLgn4A/zcz/buT5hszMiJjXVSUzdwI7AUZHR3NsbKzttn30+pu4Yl9dE5S2rztizBUw5qPbf9FYbxvTJxMTE3SSA2fS0V9NRDybRsK/PjM/W4ofioiTMvPBMnxzqJQfBFY37b6qlElSV802ldP5+53N3gngKuC+zPxQ06ZdwOayvBm4qan8zWUWz1nA4cx8sN3zS5Lmr5Oe/suBNwH7IuLrpewvgcuBGyJiK/A94Pyy7RbgHGASeAy4uINzS5La0HbSLzdkY5bNG2aon8Al7Z5PktQ535ErSRWp6/a/pKr5UDaTvqRKTZ/hU8tFwOEdSaqISV+SKuLwjiRRz3i/SV+S2jCsFwmTviRNM6wJvRWO6UtSRezpS1KLFsNn8trTl6SK2NOXpKNYDL37ZiZ9SerQMD2/3+EdSaqISV+SKuLwjiT1yCAO+9jTl6SK2NOXpD5byHf82tOXpIrY05ekBdTvXr9JX5IGRD8uAA7vSFJFTPqSVBGTviRVxKQvSRUx6UtSRfqe9CNiY0R8MyImI2JHv88vSTXra9KPiGOAjwFnA6cAF0bEKf1sgyTVrN89/TOAycy8PzOfAMaBTX1ugyRVKzKzfyeLOA/YmJlvKetvAs7MzLc11dkGbCurLwW+2cEpVwA/6mD/YWTMdTDmOrQb84sy84UzbRi4d+Rm5k5gZzeOFRF3ZuZoN441LIy5DsZch17E3O/hnYPA6qb1VaVMktQH/U76XwHWRsTJEXEscAGwq89tkKRq9XV4JzOPRMTbgC8AxwBXZ+Y9PTxlV4aJhowx18GY69D1mPt6I1eStLB8R64kVcSkL0kVGfqkP9djHSLiuIj4dNl+R0SsWYBmdlULMb8zIu6NiLsiYndEvGgh2tlNrT6+IyJ+LyIyIoZ+al8rMUfE+eV3fU9E/GO/29htLfxt/0pE3BYRXyt/3+csRDu7KSKujohDEXH3LNsjIj5SfiZ3RcRpHZ0wM4f2i8bN4O8AvwocC/wncMq0On8MfKIsXwB8eqHb3YeY1wPPLctvrSHmUu95wO3AHmB0odvdh9/zWuBrwIll/ZcXut19iHkn8NayfAqwf6Hb3YW4XwGcBtw9y/ZzgM8DAZwF3NHJ+Ya9p9/KYx02AdeW5RuBDRERfWxjt80Zc2belpmPldU9NN4PMcxafXzH+4APAD/tZ+N6pJWY/xD4WGY+ApCZh/rcxm5rJeYEfqksLwP+q4/t64nMvB14+ChVNgHXZcMeYHlEnNTu+YY96a8EHmhaP1DKZqyTmUeAw8AL+tK63mgl5mZbafQShtmcMZeXvKsz82YWh1Z+zy8BXhIR/xYReyJiY99a1xutxPxXwBsj4gBwC/D2/jRtQc33f/6oBu4xDOqeiHgjMAr87kK3pZci4lnAh4AtC9yUfltCY4hnjMarudsjYl1m/mQhG9VjFwLXZOYVEfEy4JMRcWpm/t9CN2xYDHtPv5XHOjxVJyKW0HhJ+OO+tK43WnqURUS8CngPcG5m/qxPbeuVuWJ+HnAqMBER+2mMe+4a8pu5rfyeDwC7MvN/M/O7wLdoXASGVSsxbwVuAMjMfweeQ+OhZItZVx9fM+xJv5XHOuwCNpfl84AvZbk7MqTmjDkifgf4OxoJf9jHeWGOmDPzcGauyMw1mbmGxn2MczPzzoVpble08rf9LzR6+UTEChrDPff3sY3d1krM3wc2AETEr9NI+j/sayv7bxfw5jKL5yzgcGY+2O7Bhnp4J2d5rENEvBe4MzN3AVfReAk4SeNmyQUL1+LOtRjzB4GlwGfKPevvZ+a5C9boDrUY86LSYsxfAF4dEfcCPwf+PDOH9lVsizFvB/4+It5B46buliHvxBERn6Jx8V5R7lVcBjwbIDM/QePexTnAJPAYcHFH5xvyn5ckaR6GfXhHkjQPJn1JqohJX5IqYtKXpIqY9CWpIiZ9SaqISV+SKvL/QAmzCmrTTuIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_sub['is_duplicate_pred'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub['is_duplicate_pred'] = df_sub['is_duplicate_pred'].apply(lambda x : 1 if x>0.5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\college\\Sem_5\\NLP\\Project\\venv\\lib\\site-packages\\xgboost\\core.py:105: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y_pred = bst.predict(dTest, ntree_limit=bst.best_ntree_limit)\n",
    "y_pred = np.where(y_pred>0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.742414748367522"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[32630,  5624],\n",
       "       [ 9997, 12393]], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.613408567822407"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "48cb8e7cdb11ca655815c41ac34bed6720108475fb3aac9b379c032798fb60bc"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
